% !TEX encoding = UTF-8 Unicode
\documentclass[a4paper, 11pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[ncais]{babel}
\usepackage{fullpage}
\usepackage{hyperref}
\usepackage[nonumberlist]{glossaries}
\usepackage{amssymb,amsmath}
\makeglossaries

\newcommand{\fvar}{\f(n,i)}
\newcommand{\pinit}{\pi (i)}
\newcommand{\ptrans}{t(i,j)}
\newcommand{\pemi}{e(x\mid i)}



\makeatletter
\renewcommand{\@seccntformat}[1]{
  \ifcsname prefix@#1\endcsname
    \csname prefix@#1\endcsname
  \else
    \csname the#1\endcsname\quad
  \fi}
\newcommand\prefix@section{Article \thesection: }
\makeatother

\title{{Mini-mémoire}\\Notes articles HMM}
\author{Jérôme \textsc{Hellinckx}}

\newglossaryentry{chaine de Markov}{
  name=chaîne de Markov,
  description={Processus stochastique subissant des transitions d'un état à l'autre dans l'espace des états et où la probabilité d'entrer à l'état suivant $j$ dépend uniquement de l'état courant $i$}
}

\newglossaryentry{etat}{
 name=état,
 description={Facteur interne non-observable d'un MMC}
 }
 
 \newglossaryentry{symbole}{
  name=symbole,
  description={Événement observable d'un MMC}
}

\newglossaryentry{ptransition}{
 name=probabilité de transition,
 description={Probabilité de faire une transition d'un \gls{etat} $i$ à un \gls{etat} $j$. Dénoté $t(i,j)$}
}

\newglossaryentry{pinitial}{
 name=probabilité de l'état initial,
 description={Pour tout état $i$, probabilité que $y_1$ prenne $i$ comme valeur. Dénoté $\pi (i)$}
}

\newglossaryentry{pemission}{
 name=probabilité d'émission,
  description={Probabilité qu'un \gls{etat} $i$ émette un \gls{symbole} $x$. C'est donc la distribution des probabilités pour chaque \gls{symbole} par \gls{etat}. Dénoté $e(x\mid i)$}
 }

\begin{document}

\renewcommand{\labelitemi}{$\bullet$}

\maketitle
\tableofcontents
\glsaddall
\printglossaries
\newpage
\section{\textit{Hidden Markov Models and their Applications in Biological Sequence Analysis}}
\subsection{Définition d'un MMC}
Un \textit{modèle de Markov caché} est un modèle statistique qui peut être utilisé pour décrire l'évolution d'événements observables qui sont dépendants de facteurs internes non-observables. On appelle l'événement observé un \textit{\gls{symbole}} et le facteur invisible sous-jacent l'observation un \textit{\gls{etat}}. 
\\Un MMC consiste donc en deux processus stochastiques, d'une part un processus invisible d'états cachés, d'autre part un processus visible de symboles observables. Les états cachés forment une \textit{\gls{chaine de Markov}} et la distribution de probabilité des symboles observés dépend de l'état sous-jacent. 
\\
\par
Formellement, on dénote la séquence de symboles observés par $\textbf{x} = x_1x_2\dotsc x_L $ et la séquence d'états sous-jacents par  $\textbf{y} = y_1y_2\dotsc y_L $ où $y_n$ est l'état sous-jacent de la $n-$ième observation $x_n$.
Chaque symbole $x_n$ prend un nombre fini de valeurs possibles de l'ensemble d'observations $O=\{O_1,O_2,\dotsc ,O_N\}$, et chaque état $y_n$ prend une valeur de l'ensemble d'états $S=\{1,2,\dotsc ,M\}$, où $N$ et $M$ dénotent respectivement le nombre d'observations distinctes et le nombre d'états distincts.
\\
On suppose que la séquence d'états finis est une \textit{chaîne de Markov en temps homogène de premier ordre}, ce qui implique que la probabilité d'entrer à l'état $j$ en $y_{n+1}$ dépend uniquement de l'état courant $i$ en $y_n$ et que cette probabilité ne change pas au cours du temps. Ainsi, on a
\begin{equation}
P\{y_{n+1}=j\mid y_n=i\}=t(i,j)
\end{equation}
$\forall i,j\in S, \forall n\geq 1$. La probabilité de faire une transition d'un état $i$ à un état $j$ est appelée \textit{\gls{ptransition}} qu'on dénote $t(i,j)$. À l'état initial $y_1$, on dénote la \textit{\gls{pinitial}} par $\pi (i)=P\{y_1=i\},\forall i\in S$. La probabilité que la $n-$ième observation soit $x_n=x$ dépend uniquement de l'état sous-jacent $y_n$, par conséquent 
\begin{equation}
P\{x_n=x\mid y_n=i\}=e(x\mid i)
\end{equation}
$\forall x\in O,\forall i\in S,\forall n\geq 1$. C'est ce qu'on appelle la \textit{probabilité d'émission} de $x$ à l'état $i$, et on la dénote par $e(x\mid i)$. 
\\
Ces trois mesures de probabilités $t(i,j)$, $\pi (i)$, et $e(x\mid i)$ spécifient complètement un MMC. On dénote l'ensemble de ces paramètres par $\Theta$.
\\
\par
On peut dès lors calculer la probabilité que le MMC générera la séquence d'observations $\textbf{x} = x_1x_2\dotsc x_L $  avec la séquence d'états sous-jacente $\textbf{y} = y_1y_2\dotsc y_L $. On a donc une probabilité jointe $P\{\textbf{x},\textbf{y}\mid \Theta\}$ qui peut être calculée par
\begin{equation}
P\{\textbf{x},\textbf{y}\mid \Theta\} = P\{\textbf{x}\mid \textbf{y},\Theta\}P\{\textbf{y}\mid \Theta\}
\end{equation}
où
\begin{equation}
P\{\textbf{x}\mid \textbf{y},\Theta\} = e(x_1\mid y_1)e(x_2\mid y_2)e(x_3\mid y_3)\dotsc e(x_L\mid y_L)
\end{equation}
\begin{equation}
P\{\textbf{y}\mid \Theta\} = \pi(y_1)t(y_1,y_2)t(y_2,y_3)\dotsc t(y_{L-1},y_L).
\end{equation}
\newpage
\subsection{Les 3 problèmes basiques d'un MMC}
\subsubsection{Problème d'évaluation}
Comment calculer la probabilité d'observation $P\{\textbf{x}\mid \Theta\}$ en se basant sur un MMC donné ? On pourrait considérer toutes les séquences d'états $\textbf{y}$ possibles pour $\textbf{x}$ donné et additionner les probabilités 
\begin{equation}
P\{\textbf{x}\mid \Theta\} = \sum_{y}P\{\textbf{x},\textbf{y}\mid \Theta\}.
\end{equation}
Ceci est cependant très couteux en calcul puisqu'il existe $M^L$ séquences d'états possibles.
\\
\par
Le \textit{forward algorithm} est un algorithme de programmation dynamique calculant efficacement $P\{\textbf{x}\mid \Theta\}$. Cet algorithme définit une \textit{forward variable} $f(n,i) $ déterminant la probabilité d'observer la séquence partielle de symboles $x_1\dotsc x_n$ et d'arriver à l'état $i$ pour $y_n$, étant donné $\Theta$
\begin{equation}
f(n,i) = P\{x_1\dotsc x_n,y_n=i\mid \Theta\}.
\end{equation}
En $n=1$, $f(1,i) = P\{x_1,i\mid \Theta\}$. Or cette probabilité d'observer $x_1$ avec $y_1 =i$ revient à joindre la probabilité d'émission de $x_1$ par $i$ et la probabilité initiale de l'état $i$. Ensuite, pour $n=2,\dotsc ,L$, afin de calculer la probabilité d'observer $x_1,\dotsc ,x_{n-1},x_{n}$ et d'arriver à l'état $i$, il suffit, pour chaque $j$ en $n-1$, de récupérer son $f(n-1,j)$ associé (probabilité d'observer $x_1,\dotsc ,x_{n-1}$ et d'arriver à $j$) en y joignant la probabilité de transition $t(j,i)$ puisqu'on passe de $j$ à $i$ ainsi que le probabilité d'émission $e(x_{n}\mid i)$ étant donné qu'on observe $x_{n}$ avec $i$, et de tous les additionner. On en déduit la formule récursive
\begin{equation}
f(n,i) = \begin{cases}
	\pinit e(x_1\mid i), & n=1.\\ 
	\sum_{j=1}^{M}[f(n-1,j)t(j,i)e(x_{n}\mid i)], & n=2,\dotsc ,L.
\end{cases}
\end{equation}
On finit par trouver la probabilité d'observation de \textbf{x} en additionnant les probabilités d'observer $x_1,\dotsc x_L$ et d'arriver à chaque état $i$ 
\begin{equation}
P\{\textbf{x}\mid \Theta\} = \sum_{i=1}^{M}f(L,i).
\end{equation}
La complexité de cet algorithme est seulement $\mathcal{O}(LM^2)$.
\\
\par
Les mêmes résultats peuvent être obtenus en utilisant un algorithme fonctionnant dans l'autre sens, appelé \textit{backward algorithm}. Cet algorithme définit une \textit{backward variable} donnant la probabilité d'observer la séquence de symbole $x_{n+1}\dotsc x_L$ après être arrivé à un état $i$ en $n$
\begin{equation}
b(n,i)=P\{x_{n+1}\dotsc x_L\mid y_n=i,\Theta\}.
\end{equation}
Cette variable $b(n,i)$ peut être calculée récursivement comme suit
\begin{equation}
b(n,i) = \begin{cases}
	1, & n=L.\\
	\sum_{j=1}^{M}[t(i,j)e(x_{n+1}\mid j)b(n+1,j)], & n=L-1,L-2,\dotsc ,1.
\end{cases}
\end{equation}
On obtient alors la probabilité d'observation de \textbf{x} 
\begin{equation}
P\{\textbf{x}\mid\Theta\} = \sum_{i=1}^{M}b(1,i)\pinit e(x_1 \mid i).
\end{equation}
\subsubsection{Problème de décodage}
Étant donné une séquence de symbole \textbf{x} et un modèle $\Theta$, quelle est la séquence d'états \textbf{y} qui explique au mieux la séquence de symboles observés ? On recherche donc le chemin [d'états] optimal $\textbf{y}^*$ qui maximise la probabilité d'observation de la séquence de symbole \textbf{x}. Soit formellement
\begin{equation}
\textbf{y}^*=\max_y P\{\textbf{y}\mid \textbf{x},\Theta\}.
\end{equation}
L'\textit{algorithme de Viterbi} permet de trouver un tel chemin. Cet algorithme définit la variable $\gamma (n,i)$ qui est le score maximum le long d'un chemin d'état $y_1\dotsc y_{n-1}$ arrivant à l'état $i$ en $y_n$ et émettant les symboles $x_1\dotsc x_n$. C'est-à-dire formellement
\begin{equation}
\gamma (n,i) = \max_{y_1,\dotsc ,y_{n-1}}P\{x_1\dotsc x_n,y_1\dotsc y_{n-1}y_n=i\mid\Theta\},
\end{equation}
calculée récursivement selon la formule
\begin{equation}
\gamma (n,i) = \begin{cases}
	\pi (i)e(x_1\mid i), & n=1.\\
	\max\limits_{j}[\gamma (n-1,j)t(j,i)e(x_{n}\mid i)], & n=2,\dotsc ,L.
\end{cases}
\end{equation}
On conclut en obtenant la probabilité d'observation maximale comme suit
\begin{equation}
P^*= \max_y P\{\textbf{x},\textbf{y}\mid\Theta\}= \max_i \gamma (L,i),
\end{equation}
et on retrouve le chemin d'états optimal $\textbf{y}^*$ en remontant les récursions qui ont menées à la probabilité maximale. L'algorithme de Viterbi trouve la séquence d'états optimale en un temps $\mathcal{O}(LM^2)$.
\\
Il est à noter que les probabilités peuvent devenir de très petits nombres \textit{float} pour de longues séquences, menant potentiellement à des problèmes pour la représentation machine. Ceci peut être résolu en changeant les probabilités en logarithmes de probabilités.
\subsubsection{Problème d'entrainement}
Soit un ensemble de séquences de symboles observés $\textbf{X}=\{\textbf{x}_1,\textbf{x}_2,\dotsc ,\textbf{x}_T\}$ qu'on souhaite représenter par un MMC. Comment peut-on choisir de manière raisonnable et adéquate les paramètres $\Theta = (\pinit,\ptrans,\pemi)$ du MMC en se basant sur ces observations ? Bien qu'il n'existe pas de manière optimale d'estimer les paramètres à partir d'un nombre limité de séquences finies de symboles, il est possible de trouver des paramètres maximisant localement la probabilité d'observation (\textit{Baum-Welch}, \textit{stochastic EM}).

\section{\textit{A linear memory algorithm for Baum-Welch training}}
\subsection{Entrainement \textit{Baum-Welch}}
Rappelons que le problème d'entrainement est de trouver un ensemble de paramètres $\Theta = (\pinit,\ptrans,\pemi)$ satisfaisant pour un MMC.
L'algorithme Baum-Welch définit une procédure itérative dans laquelle les probabilités d'émission $\pemi$ et de transition $\ptrans$ dans l'itération $n+1$ sont mises au nombre de fois que chaque transition et émission est attendue à être utilisée lors de l'analyse de la séquence d'entrainement avec l'ensemble des probabilités d'émission et de transition dérivées dans l'itération précédente $n$.

\section{\textit{Implementing EM and Viterbi algorithms for Hidden Markov Model in linear memory}}
\subsection{Définition d'un MMC}
Un MMC peut être décrit comme une machine à état fini stochastique pour laquelle chaque transition entre états cachés se termine par une émission de symbole. Un MMC peut être représenté par un graphe dirigé avec $N$ états où chaque état peut émettre soit un caractère discret, soit une valeur continue tirée depuis une fonction de densité de probabilité (\textit{PDF}). Les paramètres suivants décrivent l'implémentation conventionnelle d'un MMC :
\begin{itemize}
	\item Un ensemble d'états $S=\{S_1,\dotsc ,S_N\}$ avec $q_t$ l'état visité à l'instant $t$;
	\item Un ensemble de fonctions de densité de probabilité $B = \{b_1(o),\dotsc ,b_N(o)\}$, décrivant les probabilités d'émission $b_j(o_t) = P(o_t \mid q_t = S_j)$ pour $1\leq j\leq N$, où $o_t$ est l'observation au temps $t$ de la séquence d'observations $O=\{O_1,\dotsc ,O_T\}$;
	\item Une matrice de probabilités de transition [d'états] $A = \{a_{i, j}\}$ pour $1\lq i, j \leq N$, où $a_{i, j}=P(q_{t+1} = S_j \mid q_t = S_i)$;
	\item Un vecteur de distributions initiales d'états $\Pi = \{\pi_1,\dotsc ,\pi_N\}$.
\end{itemize}

\section{\textit{Using hidden Markov models to analyze gene expression time course data}}
\subsection{Définition formelle d'un problème de \textit{clustering}}
Soit $n$ séquences $O^i$ pouvant être de longueur différente, avec un ensemble d'indices $ \mathcal{I} = \{1,2,\dotsc ,n\}$ et un entier fixé $K \ll n$. Calculer une partition $\mathcal{C} = (C_1,C_2,\dotsc ,C_K)$ de $\mathcal{I}$ et les MMCs $\lambda_1,\dotsc ,\lambda_K$ qui maximisent la fonction
\begin{equation}
f(\mathcal{C}) = \prod_{k=1}^{K}\prod_{i\in C_k} L(O^i \mid \lambda_k),
\end{equation}
où $L(O^i \mid \lambda_k)$ dénote la \textit{likelihood function}, la densité de probabilité de générer la séquence $O^i$ avec le modèle $\lambda_k : (O^i \mid \lambda_k) := P(O^i \mid \lambda_k)$.
\subsection{Proposition de résolution}
L'approche de la vraisemblance maximum (\textit{maximum likelihood}) pour résoudre un \textit{cluster problem} de MMC est proposée, étant donnée une collection $K$ initiale de MMCs $\lambda_1^0,\dotsc ,\lambda_K^0$.
\begin{enumerate}
	\item Itération $t\in \{1,2,\dotsc\} :$
	\begin{itemize}
		\item[(a)] Générer un nouveau partitionnement des séquences en assignant chaque séquence $O^i$ au modèle $k$ pour lequel la vraisemblance $L(O^i\mid \lambda_k^{t-1})$ est maximale. 
		\item[(b)]
	\end{itemize} Calculer les nouveaux paramètres $\lambda_1^t,\dotsc ,\lambda_K^t$ en utilisant un algorithme de réestimation avec leur paramètres précédents $\lambda_1^{t-1},\dotsc ,\lambda_K^{t-1}$ et leurs séquences assignées.
	\item Stop si (1) l'amélioration de la fonction est plus petite qu'une limite donnée $\varepsilon$, (2) le groupement des séquences est inchangé ou (3) la limite d'iterations est atteinte.
\end{enumerate}

\subsection{Déterminer le nombre de \textit{clusters}}
Déterminer le nombre de \textit{clusters} pose un problème particulier dans ce cas puisqu'il faut ici spécifier une \textit{collection} de modèles. Généralement on choisit des modèles initiaux en se basant sur des prototypes de comportement. Le nombre de modèles suit ensuite deux règles simples.
\begin{enumerate}
	\item Si un cluster contient très peu de profils, supprimer le cluster et réassigner les profils aux clusters restants. 
	\item Si un cluster contient trop de profils, le séparer en deux. Pour cela, on copie le modèle en changeant aléatoirement les paramètres des copies de façon uniforme et indépendante. 
\end{enumerate}

\subsection{Données manquantes}
On ajoute aux probabilités d'émission une valeur constante représentant la fréquence de données manquantes. Cette constante n'est pas modifiée par l'étape Baum-Welch dans l'algorithme de clustering. 

\section{\textit{Robust inference of groups in gene expression time-courses using mixtures of HMMs}}

\end{document}