% !TEX encoding = UTF-8 Unicode
\documentclass[a4paper, 11pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[francais]{babel}
\usepackage{fullpage}
\usepackage{hyperref}
\usepackage[nonumberlist]{glossaries}
\usepackage{amssymb,amsmath}
\makeglossaries

\newcommand{\fvar}{\f(n,i)}
\newcommand{\pinit}{\pi (i)}
\newcommand{\ptrans}{t(i,j)}
\newcommand{\pemi}{e(x\mid i)}

\makeatletter
\renewcommand{\@seccntformat}[1]{
  \ifcsname prefix@#1\endcsname
    \csname prefix@#1\endcsname
  \else
    \csname the#1\endcsname\quad
  \fi}
\newcommand\prefix@section{Article \thesection: }
\makeatother

\title{{Mini-mémoire}\\Notes articles HMM}
\author{Jérôme \textsc{Hellinckx}}

\newglossaryentry{chaine de Markov}{
  name=chaîne de Markov,
  description={Processus stochastique subissant des transitions d'un état à l'autre dans l'espace des états et où la probabilité d'entrer à l'état suivant $j$ dépend uniquement de l'état courant $i$}
}

\newglossaryentry{etat}{
 name=état,
 description={Facteur interne non-observable d'un MMC}
 }
 
 \newglossaryentry{symbole}{
  name=symbole,
  description={Événement observable d'un MMC}
}

\newglossaryentry{ptransition}{
 name=probabilité de transition,
 description={Probabilité de faire une transition d'un \gls{etat} $i$ à un \gls{etat} $j$. Dénoté $t(i,j)$}
}

\newglossaryentry{pinitial}{
 name=probabilité de l'état initial,
 description={Pour tout état $i$, probabilité que $y_1$ prenne $i$ comme valeur. Dénoté $\pi (i)$}
}

\newglossaryentry{pemission}{
 name=probabilité d'émission,
  description={Probabilité qu'un \gls{etat} $i$ émette un \gls{symbole} $x$. C'est donc la distribution des probabilités pour chaque \gls{symbole} par \gls{etat}. Dénoté $e(x\mid i)$}
 }

\begin{document}
\maketitle
\tableofcontents
\glsaddall
\printglossaries
\newpage
\section{\textit{Hidden Markov Models and their Applications in Biological Sequence Analysis}}
\subsection{Définition d'un MMC}
Un \textit{modèle de Markov caché} est un modèle statistique qui peut être utilisé pour décrire l'évolution d'événements observables qui sont dépendants de facteurs internes non-observables. On appelle l'événement observé un \textit{\gls{symbole}} et le facteur invisible sous-jacent l'observation un \textit{\gls{etat}}. 
\\Un MMC consiste donc en deux processus stochastiques, d'une part un processus invisible d'états cachés, d'autre part un processus visible de symboles observables. Les états cachés forment une \textit{\gls{chaine de Markov}} et la distribution de probabilité des symboles observés dépend de l'état sous-jacent. 
\\
\par
Formellement, on dénote la séquence de symboles observés par $\textbf{x} = x_1x_2\dotsc x_L $ et la séquence d'états sous-jacents par  $\textbf{y} = y_1y_2\dotsc y_L $ où $y_n$ est l'état sous-jacent de la $n-$ième observation $x_n$.
Chaque symbole $x_n$ prend un nombre fini de valeurs possibles de l'ensemble d'observations $O=\{O_1,O_2,\dotsc ,O_N\}$, et chaque état $y_n$ prend une valeur de l'ensemble d'états $S=\{1,2,\dotsc ,M\}$, où $N$ et $M$ dénotent respectivement le nombre d'observations distinctes et le nombre d'états distincts.
\\
On suppose que la séquence d'états finis est une \textit{chaîne de Markov en temps homogène de premier ordre}, ce qui implique que la probabilité d'entrer à l'état $j$ en $y_{n+1}$ dépend uniquement de l'état courant $i$ en $y_n$ et que cette probabilité ne change pas au cours du temps. Ainsi, on a
\begin{equation}
P\{y_{n+1}=j\mid y_n=i\}=t(i,j)
\end{equation}
$\forall i,j\in S, \forall n\geq 1$. La probabilité de faire une transition d'un état $i$ à un état $j$ est appelée \textit{\gls{ptransition}} qu'on dénote $t(i,j)$. À l'état initial $y_1$, on dénote la \textit{\gls{pinitial}} par $\pi (i)=P\{y_1=i\},\forall i\in S$. La probabilité que la $n-$ième observation soit $x_n=x$ dépend uniquement de l'état sous-jacent $y_n$, par conséquent 
\begin{equation}
P\{x_n=x\mid y_n=i\}=e(x\mid i)
\end{equation}
$\forall x\in O,\forall i\in S,\forall n\geq 1$. C'est ce qu'on appelle la \textit{probabilité d'émission} de $x$ à l'état $i$, et on la dénote par $e(x\mid i)$. 
\\
Ces trois mesures de probabilités $t(i,j)$, $\pi (i)$, et $e(x\mid i)$ spécifient complètement un MMC. On dénote l'ensemble de ces paramètres par $\Theta$.
\\
\par
On peut dès lors calculer la probabilité que le MMC générera la séquence d'observations $\textbf{x} = x_1x_2\dotsc x_L $  avec la séquence d'états sous-jacente $\textbf{y} = y_1y_2\dotsc y_L $. On a donc une probabilité jointe $P\{\textbf{x},\textbf{y}\mid \Theta\}$ qui peut être calculée par
\begin{equation}
P\{\textbf{x},\textbf{y}\mid \Theta\} = P\{\textbf{x}\mid \textbf{y},\Theta\}P\{\textbf{y}\mid \Theta\}
\end{equation}
où
\begin{equation}
P\{\textbf{x}\mid \textbf{y},\Theta\} = e(x_1\mid y_1)e(x_2\mid y_2)e(x_3\mid y_3)\dotsc e(x_L\mid y_L)
\end{equation}
\begin{equation}
P\{\textbf{y}\mid \Theta\} = \pi(y_1)t(y_1,y_2)t(y_2,y_3)\dotsc t(y_{L-1},y_L).
\end{equation}
\newpage
\subsection{Les 3 problèmes basiques d'un MMC}
\subsubsection{Problème d'évaluation}
Comment calculer la probabilité d'observation $P\{\textbf{x}\mid \Theta\}$ en se basant sur un MMC donné ? On pourrait considérer toutes les séquences d'états $\textbf{y}$ possibles pour $\textbf{x}$ donné et additionner les probabilités 
\begin{equation}
P\{\textbf{x}\mid \Theta\} = \sum_{y}P\{\textbf{x},\textbf{y}\mid \Theta\}.
\end{equation}
Ceci est cependant très couteux en calcul puisqu'il existe $M^L$ séquences d'états possibles.
\\
\par
Le \textit{forward algorithm} est un algorithme de programmation dynamique calculant efficacement $P\{\textbf{x}\mid \Theta\}$. Cet algorithme définit une \textit{forward variable} $f(n,i) $ déterminant la probabilité d'observer la séquence partielle de symboles $x_1\dotsc x_n$ et d'arriver à l'état $i$ pour $y_n$, étant donné $\Theta$
\begin{equation}
f(n,i) = P\{x_1\dotsc x_n,y_n=i\mid \Theta\}.
\end{equation}
En $n=1$, $f(1,i) = P\{x_1,i\mid \Theta\}$. Or cette probabilité d'observer $x_1$ avec $y_1 =i$ revient à joindre la probabilité d'émission de $x_1$ par $i$ et la probabilité initiale de l'état $i$. Ensuite, pour $n=2,\dotsc ,L$, afin de calculer la probabilité d'observer $x_1,\dotsc ,x_{n-1},x_{n}$ et d'arriver à l'état $i$, il suffit, pour chaque $j$ en $n-1$, de récupérer son $f(n-1,j)$ associé (probabilité d'observer $x_1,\dotsc ,x_{n-1}$ et d'arriver à $j$) en y joignant la probabilité de transition $t(j,i)$ puisqu'on passe de $j$ à $i$ ainsi que le probabilité d'émission $e(x_{n}\mid i)$ étant donné qu'on observe $x_{n}$ avec $i$, et de tous les additionner. On en déduit la formule récursive
\begin{equation}
f(n,i) = \begin{cases}
	\pinit e(x_1\mid i), & n=1.\\ 
	\sum_{j=1}^{M}[f(n-1,j)t(j,i)e(x_{n}\mid i)], & n=2,\dotsc ,L.
\end{cases}
\end{equation}
On finit par trouver la probabilité d'observation de \textbf{x} en additionnant les probabilités d'observer $x_1,\dotsc x_L$ et d'arriver à chaque état $i$ 
\begin{equation}
P\{\textbf{x}\mid \Theta\} = \sum_{i=1}^{M}f(L,i).
\end{equation}
La complexité de cet algorithme est seulement $\mathcal{O}(LM^2)$.
\\
\par
Les mêmes résultats peuvent être obtenus en utilisant un algorithme fonctionnant dans l'autre sens, appelé \textit{backward algorithm}. Cet algorithme définit une \textit{backward variable} donnant la probabilité d'observer la séquence de symbole $x_{n+1}\dotsc x_L$ après être arrivé à un état $i$ en $n$
\begin{equation}
b(n,i)=P\{x_{n+1}\dotsc x_L\mid y_n=i,\Theta\}.
\end{equation}
Cette variable $b(n,i)$ peut être calculée récursivement comme suit
\begin{equation}
b(n,i) = \begin{cases}
	1, & n=L.\\
	\sum_{j=1}^{M}[t(i,j)e(x_{n+1}\mid j)b(n+1,j)], & n=L-1,L-2,\dotsc ,1.
\end{cases}
\end{equation}
On obtient alors la probabilité d'observation de \textbf{x} 
\begin{equation}
P\{\textbf{x}\mid\Theta\} = \sum_{i=1}^{M}b(1,i)\pinit e(x_1 \mid i).
\end{equation}
\subsubsection{Problème de décodage}
Étant donné une séquence de symbole \textbf{x} et un modèle $\Theta$, quelle est la séquence d'états \textbf{y} qui explique au mieux la séquence de symboles observés ? On recherche donc le chemin [d'états] optimal $\textbf{y}^*$ qui maximise la probabilité d'observation de la séquence de symbole \textbf{x}. Soit formellement
\begin{equation}
\textbf{y}^*=\max_y P\{\textbf{y}\mid \textbf{x},\Theta\}.
\end{equation}
L'\textit{algorithme de Viterbi} permet de trouver un tel chemin. Cet algorithme définit la variable $\gamma (n,i)$ qui est le score maximum le long d'un chemin d'état $y_1\dotsc y_{n-1}$ arrivant à l'état $i$ en $y_n$ et émettant les symboles $x_1\dotsc x_n$. C'est-à-dire formellement
\begin{equation}
\gamma (n,i) = \max_{y_1,\dotsc ,y_{n-1}}P\{x_1\dotsc x_n,y_1\dotsc y_{n-1}y_n=i\mid\Theta\},
\end{equation}
calculée récursivement selon la formule
\begin{equation}
\gamma (n,i) = \begin{cases}
	\pi (i)e(x_1\mid i), & n=1.\\
	\max\limits_{j}[\gamma (n-1,j)t(j,i)e(x_{n}\mid i)], & n=2,\dotsc ,L.
\end{cases}
\end{equation}
On conclut en obtenant la probabilité d'observation maximale comme suit
\begin{equation}
P^*= \max_y P\{\textbf{x},\textbf{y}\mid\Theta\}= \max_i \gamma (L,i),
\end{equation}
et on retrouve le chemin d'états optimal $\textbf{y}^*$ en remontant les récursions qui ont menées à la probabilité maximale. L'algorithme de Viterbi trouve la séquence d'états optimale en un temps $\mathcal{O}(LM^2)$.
\\
Il est à noter que les probabilités peuvent devenir de très petits nombres \textit{float} pour de longues séquences, menant potentiellement à des problèmes pour la représentation machine. Ceci peut être résolu en changeant les probabilités en logarithmes de probabilités.
\subsubsection{Problème d'entrainement}
Soit un ensemble de séquences de symboles observés $\textbf{X}=\{\textbf{x}_1,\textbf{x}_2,\dotsc ,\textbf{x}_T\}$ qu'on souhaite représenter par un MMC. Comment peut-on choisir de manière raisonnable et adéquate les paramètres $\Theta = (\pinit,\ptrans,\pemi)$ du MMC en se basant sur ces observations ? Bien qu'il n'existe pas de manière optimale d'estimer les paramètres à partir d'un nombre limité de séquences finies de symboles, il est possible de trouver des paramètres maximisant localement la probabilité d'observation (\textit{Baum-Welch}, \textit{stochastic EM}).

\section{\textit{A linear memory algorithm for Baum-Welch training}}
\subsection{Entrainement \textit{Baum-Welch}}
Rappelons que le problème d'entrainement est de trouver un ensemble de paramètres $\Theta = (\pinit,\ptrans,\pemi)$ satisfaisant pour un MMC.
L'algorithme Baum-Welch définit une procédure itérative dans laquelle les probabilités d'émission $\pemi$ et de transition $\ptrans$ dans l'itération $n+1$ sont mises au nombre de fois que chaque transition et émission est attendue à être utilisée lors de l'analyse de la séquence d'entrainement avec l'ensemble des probabilités d'émission et de transition dérivées dans l'itération précédente $n$.

\end{document}